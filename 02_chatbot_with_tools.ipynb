{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a863075d",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/GenAIHub/agents-workshop/blob/main/02_chatbot_with_tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22c5d4a-3134-413c-81fe-dd9752fbeb66",
   "metadata": {},
   "source": [
    "## Enhancing the Chatbot with Tools\n",
    "\n",
    "To answer questions beyond the chatbot's LLM built-in knowledge, we'll add a web search tool to help the bot find relevant information online and give better responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb3fc08",
   "metadata": {},
   "source": [
    "#### Requirements\n",
    "Before we start, install the requirements to use the [Tavily Search Engine](https://python.langchain.com/v0.2/docs/integrations/tools/tavily_search/), and set your [TAVILY_API_KEY](https://tavily.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7451151f-41fc-4af0-9359-024ae51b7225",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U tavily-python\n",
    "%pip install -U langchain langchain-core langchain-openai langchain-community \n",
    "%pip install -U langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f24c8c",
   "metadata": {},
   "source": [
    "Set API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c52923c-5665-4f8c-a1ba-9799e369c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://app-ads-sbx-openai-sw.openai.azure.com\"\n",
    "os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2023-07-01-preview\"\n",
    "os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"] = \"gpt-4o\"\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41d861c",
   "metadata": {},
   "source": [
    "Initialize the Azure LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6525bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "# Fetching environment variables\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "\n",
    "if not all([api_key, endpoint, api_version, deployment_name]):\n",
    "    raise ValueError(\"One or more environment variables are missing.\")\n",
    "\n",
    "# Initialize the Azure LLM\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_key=api_key,\n",
    "    azure_endpoint=endpoint,\n",
    "    azure_deployment=deployment_name,\n",
    "    openai_api_version=api_version,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591ce9ba-c431-4165-b815-25c944ef7cdb",
   "metadata": {},
   "source": [
    "Adding a Web Search Tool <br>\n",
    "<br>\n",
    "Let's add a web search tool to our chatbot to enable it to search the web for information. We can integrate this using an external API or a custom function. <br>\n",
    "In this case, we will make use of the **Tavily API** to search the web. <br>\n",
    "For simplicity, LangChain offers a pre-built tool that we can use out-of-the-box!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c8978e-c07d-4dd0-a97b-0ce3a723eea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Tavily search tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Initialize the Tavily tool\n",
    "# We limit the max results Tavily returns to 2\n",
    "search_tool = TavilySearchResults(max_results=2)\n",
    "tools = [search_tool]\n",
    "\n",
    "# Bind the tools to the LLM\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3336316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the Tavily search tool with a sample query to see how it works.\n",
    "# This simulates the chatbot using the tool to find information about \"nodes\" in LangGraph.\n",
    "search_tool.invoke(\"What's a 'node' in LangGraph?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f503f02-d23d-42e8-9b5d-eb2681b242f4",
   "metadata": {},
   "source": [
    "The results are page summaries our chat bot can use to answer questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565726c0",
   "metadata": {},
   "source": [
    "Creating a `StateGraph`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f1fc14-cd91-4cd4-9f2e-1d007f8beafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the state and graph, similar to last notebook\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# Define the chatbot function\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Add the chatbot node to the graph\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "graph_builder.set_entry_point(\"chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a62bda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "# Use a prebuilt ToolNode (offered by LangGraph itself) to handle tool calls.\n",
    "# ToolNode will call the correct tool based on the output of our chatbot!\n",
    "tool_node = ToolNode(tools=[search_tool])\n",
    "\n",
    "# Add the toolnode to the graph\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Define conditional edges to manage the flow of the graph.\n",
    "# The condition will route to \"tools\" if tool calls are present, \n",
    "# and to \"__end__\" if no tool calls are made.\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "# Each time a tool is called, we return to the chatbot to decide the next step.\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# Compile the graph\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aa67c2-dd1b-4bf2-8c64-eea44296d15f",
   "metadata": {},
   "source": [
    "Let's visualize the graph we've built. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b49509c-9d97-457c-a76a-c495fb30ccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59593ef-5073-4279-931e-828dae971f23",
   "metadata": {},
   "source": [
    "Now we can ask the bot questions outside its training data. <br>\n",
    "Try asking it what the current weather in LA is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051dc374-67cc-4371-9dd1-221e07593148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"\\n\\nUser: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
    "        for value in event.values():\n",
    "            if isinstance(value[\"messages\"][-1], BaseMessage):\n",
    "                print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d3c04d",
   "metadata": {},
   "source": [
    "### **Built your own tool**\n",
    "\n",
    "In this section we will built our own image generator tool with 'DALL-E'. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b79c052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import json\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.tools import StructuredTool\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=\"2024-02-01\",\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=endpoint,\n",
    "    azure_deployment=\"dall-e-3\"\n",
    ")\n",
    "\n",
    "# The function to be called whenever the tool is invoked\n",
    "def generate_dalle_image(prompt: str):\n",
    "\n",
    "    # Generate an image with DALL-E\n",
    "    result = client.images.generate(\n",
    "        model=\"dalle3\",  \n",
    "        prompt=prompt,\n",
    "        n=1\n",
    "    )\n",
    "\n",
    "    json_response = json.loads(result.model_dump_json())\n",
    "\n",
    "    # Retrieve the generated image\n",
    "    image_url = json_response[\"data\"][0][\"url\"]  # extract image URL from response\n",
    "\n",
    "    display(Image(url=image_url))\n",
    "\n",
    "    return 'Image generated successfully'\n",
    "\n",
    "# A class describing the input arguments of the function behind our tool\n",
    "class ImageGeneratorInput(BaseModel):\n",
    "    prompt: str = Field(\n",
    "        description=\"The detailed prompt that will be given to the dall-e-3 model to generate the image.\"\n",
    "    )\n",
    "\n",
    "# Create the tool\n",
    "# The description is very important as it provides the LLM with the knowledge of WHEN to call the tool\n",
    "# The args_schema is very important as it provides the LLM with the knowledge of HOW to call the tool\n",
    "image_generator_tool = StructuredTool.from_function(\n",
    "    func=generate_dalle_image,\n",
    "    name=\"image_generator\",\n",
    "    description=\"Generate an image given a detailed description through the use of the dall-e-3 model.\",\n",
    "    args_schema=ImageGeneratorInput,\n",
    "    return_direct=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee222a0f",
   "metadata": {},
   "source": [
    "#### **Question (optional):**\n",
    "\n",
    "The following code builds the new graph with our new tool. <br>\n",
    "However, it does not work! <br>\n",
    "Something is missing, can you figure out what important step was looked over?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8495d6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the image_generator_tool to our tools\n",
    "tools = [search_tool, image_generator_tool]\n",
    "\n",
    "# -----------------------------------------------\n",
    "\n",
    "new_graph_builder = StateGraph(State)\n",
    "\n",
    "# Add the chatbot node to the graph\n",
    "new_graph_builder.add_node(\"chatbot\", chatbot)\n",
    "new_graph_builder.set_entry_point(\"chatbot\")\n",
    "\n",
    "# Use a prebuilt ToolNode (offered by LangGraph itself) to handle tool calls.\n",
    "# ToolNode will call the correct tool based on the output of our chatbot!\n",
    "tool_node = ToolNode(tools=tools)\n",
    "\n",
    "# Add the toolnode to the graph\n",
    "new_graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Define conditional edges to manage the flow of the graph.\n",
    "# The condition will route to \"tools\" if tool calls are present, \n",
    "# and to \"__end__\" if no tool calls are made.\n",
    "new_graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "# Each time a tool is called, we return to the chatbot to decide the next step.\n",
    "new_graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# Compile the graph\n",
    "new_graph = new_graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d6946b",
   "metadata": {},
   "source": [
    "#### **Solution**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034b4afd",
   "metadata": {},
   "source": [
    "Recall that chatbot makes use of **'llm_with_tools'**! <br>\n",
    "Our LLM has not been updated yet to be bound to our newly updated list of tools. <br>\n",
    "As a result, the LLM has no knowledge of this new tool and will never call it. <br>\n",
    "All we did in the code above was ensure that our graph knew of its existence.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffea26b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "tools = [search_tool, image_generator_tool]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cf94ac",
   "metadata": {},
   "source": [
    "Try out the new tool! <br>\n",
    "Ask the system to generate an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6414ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"\\n\\nUser: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    for event in new_graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
    "        for value in event.values():\n",
    "            if isinstance(value[\"messages\"][-1], BaseMessage):\n",
    "                print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89da9e85-2e5d-49c2-8cbd-572cbdb89135",
   "metadata": {},
   "source": [
    "**Congrats!** You've created a conversational agent in langgraph that can use a search engine to retrieve updated information when needed. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
